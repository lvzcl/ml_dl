{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./MNIST_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤如下\n",
    "    1.get_inputs\n",
    "    2.generator\n",
    "    3.discrimitor\n",
    "    4.loss optimizer\n",
    "    5.train\n",
    "    6.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs(noise_size, image_height, image_width, image_depth):\n",
    "    real_images = tf.placeholder(tf.float32, shape=[None, image_height, image_width, image_depth], name='real_images')\n",
    "    noise_vec = tf.placeholder(tf.float32, shape=[None, noise_size], name='noise_vector')\n",
    "    return real_images, noise_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def generator(noise_img, is_train=True, alpha=0.01):\n",
    "def generator(noise_img, is_train=True, alpha=0.01):\n",
    "\n",
    "    \"\"\"\n",
    "    @Author: Nelson Zhao\n",
    "    --------------------\n",
    "    :param noise_img: 噪声信号，tensor类型\n",
    "    :param output_dim: 生成图片的depth\n",
    "    :param is_train: 是否为训练状态，该参数主要用于作为batch_normalization方法中的参数使用\n",
    "    :param alpha: Leaky ReLU系数\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=(not is_train)):\n",
    "        # 100 x 1 to 4 x 4 x 512\n",
    "        # 全连接层\n",
    "        layer1 = tf.layers.dense(noise_img, 4*4*512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        # batch normalization\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train)\n",
    "        # Leaky ReLU\n",
    "        layer1 = tf.maximum(alpha * layer1, layer1)\n",
    "        # dropout\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)\n",
    "        \n",
    "        # 4 x 4 x 512 to 7 x 7 x 256\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding='valid')\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.maximum(alpha * layer2, layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)\n",
    "        \n",
    "        # 7 x 7 256 to 14 x 14 x 128\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.maximum(alpha * layer3, layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)\n",
    "        \n",
    "        # 14 x 14 x 128 to 28 x 28 x 1\n",
    "        logits = tf.layers.conv2d_transpose(layer3, 1, 3, strides=2, padding='same')\n",
    "        # MNIST原始数据集的像素范围在0-1，这里的生成图片范围为(-1,1)\n",
    "        # 因此在训练时，记住要把MNIST像素范围进行resize\n",
    "        outputs = tf.tanh(logits)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_vec, is_train=True, alpha=0.01):\n",
    "    #这儿使用反卷积实现\n",
    "    #将noise_vec输出为4*4*512大小的向量，然后reshape成[batch_size, 4, 4, 512]大小的向量\n",
    "    with tf.variable_scope('generator',reuse= (not is_train)):\n",
    "        layer1 = tf.layers.dense(noise_vec, 4*4*512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        #BN和leaky_relu\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train)\n",
    "        layer1 = tf.maximum(layer1, alpha * layer1)\n",
    "        #dropout\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)\n",
    "        \n",
    "        #4*4*512 => 7*7*256\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding='valid')\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.maximum(layer2, alpha * layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)\n",
    "        \n",
    "        #7*7*256 ==> 14*14*128\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.maximum(layer3, alpha * layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)\n",
    "        \n",
    "        #14*14*128 ==> 28*28*1\n",
    "        logits = tf.layers.conv2d_transpose(layer3, 1, 3, strides=2, padding='same')\n",
    "        output = tf.tanh(logits)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrimitor(input_images, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('discrimitor', reuse = reuse):\n",
    "        layer1 = tf.layers.conv2d(input_images, 128, 3, strides=2, padding='same')\n",
    "        layer1 = tf.maximum(layer1, alpha*layer1)\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)\n",
    "\n",
    "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding='same')\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=True)\n",
    "        layer2 = tf.maximum(layer2, alpha*layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=0.8)\n",
    "\n",
    "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=True)\n",
    "        layer3 = tf.maximum(layer3, alpha*layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=0.8)\n",
    "        #最后连接一个全连接层，输出一个值\n",
    "        \n",
    "        layer3 = tf.reshape(layer3, (-1, 4*4*512))\n",
    "        logits = tf.layers.dense(layer3, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = mnist.train.images[0]\n",
    "noise_size = 100\n",
    "learning_rate = 0.001\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(input_img, input_noise):\n",
    "    g_outputs = generator(input_noise, is_train=True)\n",
    "    d_real_logits, d_real_outputs = discrimitor(input_img)\n",
    "    d_fake_logits, d_fake_outputs = discrimitor(g_outputs, reuse=True)\n",
    "    \n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake_logits, labels=tf.ones_like(d_fake_outputs)))\n",
    "    d_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real_logits,\n",
    "                                                                        labels = tf.ones_like(d_real_outputs)))\n",
    "    d_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake_logits,\n",
    "                                                                        labels = tf.zeros_like(d_fake_outputs)))\n",
    "    d_loss = d_real_loss + d_fake_loss\n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer(g_loss, d_loss, learning_rate):\n",
    "    training_variables = tf.trainable_variables()\n",
    "    g_vars = [var for var in training_variables if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in training_variables if var.name.startswith('discrimitor')]\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(samples):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=20, sharex=True, sharey=True, figsize=(40, 2))\n",
    "    for img, ax in zip(samples, axes):\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "def show_generator_output(sess, n_images, input_noise):\n",
    "    cmap = \"Greys_r\"\n",
    "    noise_shape = input_noise.get_shape().as_list()[-1]\n",
    "    examples_noise = np.random.uniform(-1, 1, size=[n_images, noise_shape])\n",
    "    samples = sess.run(generator(input_noise,False), feed_dict={input_noise:examples_noise})\n",
    "    result = np.squeeze(samples, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoches = 10\n",
    "n_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data_shape, n_samples):\n",
    "    #tf.reset_default_graph()\n",
    "    real_images, noise_vec = get_inputs(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "    g_loss, d_loss = get_loss(real_images, noise_vec)\n",
    "    g_opt, d_opt = optimizer(g_loss, d_loss, learning_rate)\n",
    "    losses = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epoches):\n",
    "            for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "                batch = mnist.train.next_batch(batch_size)\n",
    "                batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3]))\n",
    "                batch_images = 2*batch_images - 1\n",
    "                batch_noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "                _ = sess.run(d_opt, feed_dict={real_images:batch_images, noise_vec:batch_noise})\n",
    "                _ = sess.run(g_opt, feed_dict={real_images:batch_images, noise_vec:batch_noise})\n",
    "                if batch_i % 2 == 0:\n",
    "                    train_loss_d = d_loss.eval({real_images: batch_images,\n",
    "                                                noise_vec: batch_noise})\n",
    "                    train_loss_g = g_loss.eval({real_images: batch_images,\n",
    "                                                noise_vec: batch_noise})\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "                    # 显示图片\n",
    "                    samples = show_generator_output(sess, n_samples, noise_vec)\n",
    "                    plot_images(samples)\n",
    "                    print(\"Epoch {}/{}....\".format(epoch+1, epoches), \n",
    "                          \"Discriminator Loss: {:.4f}....\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}....\". format(train_loss_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.... Discriminator Loss: 2.9664.... Generator Loss: 0.1316....\n",
      "Epoch 1/10.... Discriminator Loss: 1.3121.... Generator Loss: 1.6352....\n",
      "Epoch 1/10.... Discriminator Loss: 0.0211.... Generator Loss: 5.1027....\n",
      "Epoch 1/10.... Discriminator Loss: 0.0409.... Generator Loss: 10.8364....\n",
      "Epoch 1/10.... Discriminator Loss: 0.1165.... Generator Loss: 8.2073....\n",
      "Epoch 1/10.... Discriminator Loss: 0.3045.... Generator Loss: 2.6170....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-756108a52195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-d7a6cd16832b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_shape, n_samples)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mbatch_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_noise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_noise\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     train_loss_d = d_loss.eval({real_images: batch_images,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    train([-1, 28, 28, 1], n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
